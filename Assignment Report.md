# Web Scraping Assignment Report

In this assignment, I've used the Pantaloons website (https://www.pantaloons.com) to scape the required data from.

#### Language used:
Python

#### Extra tools:
Postman - https://www.postman.com/home

#### Libraries/Modules used:
- requests
- json
- csv
- pandas
- matplotlib + seaborn

#### How I approached the assignment:
First was the task of inspecting the website in order to find the locations of the store and connecting to the api. In order to get the data from the api, I used Postman API Platform and lastly, extracted all the data using Jupyter Notebook. Next was task was to save the data into a csv file, a segment of that csv file can be found in the Jupyter Noteboook itself. After that, a bit data analysis was performed in the Notebook to make it more understandable.
##### Note - 
*1) The csv file uploaded here is a slightly cleaner version of the original, but the file has only been formatted for a better presentation and readeability of the data and the real extracted content was not modified by any means. The same changes for type/formatting in the dataset have been made into the Notebook as well*
<br>*2) Please find all the specifications regarding the extracted data in the Jupyter Notebook itself.*

#### The data:
The final data (columns) saved in csv file includes:
- Retek code
- Name of store
- City
- Pincode
- Address
- Latitude
- Longitude
- Contact
- WhatsApp
- Manager Contact
- Opening Time
- Closing Time

#### Final Words
My final product is a result of multiple trail processes till I found the method that worked for me. Web scraping can be done in a number of ways and this is just one of those methods. I had fun doing this assigment, thank you. 
